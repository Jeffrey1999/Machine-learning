{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1J12hiU51QaUf4IDiQQS0SSQLW-bY-ONm",
      "authorship_tag": "ABX9TyPvn6sfGqJK9EonwPXyZKJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeffrey1999/Machine-learning/blob/main/yolov8_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXSVbcsu161Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c565871b-940f-45f6-c6c8-60ca8b7f7289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package from PyPI\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "m1Oyab2c70ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4eec17-63b2-4ced-df43-62be6affb94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.75-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.75-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.75 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import math, os, random, cv2, numpy, torch\n",
        "import torch.nn as nn\n",
        "from ultralytics import YOLO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU41z-F_Y1X4",
        "outputId": "8ddb9285-5bcc-42d2-aec0-43703cbe319d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original yolov8n\n",
        "model_n=YOLO('yolov8n.pt')\n",
        "print(f\"yolov8-nano: {sum(p.numel() for p in model_n.parameters())/1e6} million parameters\")\n",
        "\n",
        "\n",
        "# model_s=YOLO('yolov8s.pt')\n",
        "# print(f\"yolov8-small: {sum(p.numel() for p in model_s.parameters())/1e6} million parameters\")\n",
        "\n",
        "print(model_n.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l45acalVY6_W",
        "outputId": "9e2b1733-12cc-43c9-8aec-aa4ad24d8268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 50.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolov8-nano: 3.1572 million parameters\n",
            "DetectionModel(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (4): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (6): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Conv(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (8): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): SPPF(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (11): Concat()\n",
            "    (12): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (14): Concat()\n",
            "    (15): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): Conv(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (17): Concat()\n",
            "    (18): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (19): Conv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (20): Concat()\n",
            "    (21): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (22): Detect(\n",
            "      (cv2): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (cv3): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv(\n",
            "            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv(\n",
            "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (dfl): DFL(\n",
            "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Backbone**\n",
        "The backbone is modified CSPDarknet53 which comprises of blocks Conv, C2f, SPPF\n",
        "\n",
        "Conv: Conv2d + BatchNorm2d + SiLU\n",
        "C2f (cross-stage partial bottleneck with 2 convolutions): Conv + Bottlenecks + Conv\n",
        "Combine high-level features with contextual information to improve detection accuracy.\n",
        "SPPF (spatial pyramid pooling fast): Conv + Maxpool2d + Conv\n",
        "Process features at various scales and pool them into a fixed-size feature map.\n",
        "(a) Conv"
      ],
      "metadata": {
        "id": "mRzn6v-HZo6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self,in_channels, out_channels,kernel_size=3,stride=1,padding=1,groups=1,activation=True):\n",
        "        super().__init__()\n",
        "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False,groups=groups)\n",
        "        self.bn=nn.BatchNorm2d(out_channels,eps=0.001,momentum=0.03)\n",
        "        self.act=nn.SiLU(inplace=True) if activation else nn.Identity()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.act(self.bn(self.conv(x)))"
      ],
      "metadata": {
        "id": "S0zPVxY2ZYcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(b) C2f**"
      ],
      "metadata": {
        "id": "M_zoiudPZ87l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 Bottleneck: staack of 2 COnv with shortcut connnection (True/False)\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,shortcut=True):\n",
        "        super().__init__()\n",
        "        self.conv1=Conv(in_channels,out_channels,kernel_size=3,stride=1,padding=1)\n",
        "        self.conv2=Conv(out_channels,out_channels,kernel_size=3,stride=1,padding=1)\n",
        "        self.shortcut=shortcut\n",
        "\n",
        "    def forward(self,x):\n",
        "        x_in=x # for residual connection\n",
        "        x=self.conv1(x)\n",
        "        x=self.conv2(x)\n",
        "        if self.shortcut:\n",
        "            x=x+x_in\n",
        "        return x\n",
        "\n",
        "# 2.2 C2f: Conv + bottleneck*N+ Conv\n",
        "class C2f(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels, num_bottlenecks,shortcut=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mid_channels=out_channels//2\n",
        "        self.num_bottlenecks=num_bottlenecks\n",
        "\n",
        "        self.conv1=Conv(in_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        # sequence of bottleneck layers\n",
        "        self.m=nn.ModuleList([Bottleneck(self.mid_channels,self.mid_channels) for _ in range(num_bottlenecks)])\n",
        "\n",
        "        self.conv2=Conv((num_bottlenecks+2)*out_channels//2,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "\n",
        "        # split x along channel dimension\n",
        "        x1,x2=x[:,:x.shape[1]//2,:,:], x[:,x.shape[1]//2:,:,:]\n",
        "\n",
        "        # list of outputs\n",
        "        outputs=[x1,x2] # x1 is fed through the bottlenecks\n",
        "\n",
        "        for i in range(self.num_bottlenecks):\n",
        "            x1=self.m[i](x1)    # [bs,0.5c_out,w,h]\n",
        "            outputs.insert(0,x1)\n",
        "\n",
        "        outputs=torch.cat(outputs,dim=1) # [bs,0.5c_out(num_bottlenecks+2),w,h]\n",
        "        out=self.conv2(outputs)\n",
        "\n",
        "        return out\n",
        "\n",
        "# sanity check\n",
        "c2f=C2f(in_channels=64,out_channels=128,num_bottlenecks=2)\n",
        "print(f\"{sum(p.numel() for p in c2f.parameters())/1e6} million parameters\")\n",
        "\n",
        "dummy_input=torch.rand((1,64,244,244))\n",
        "dummy_input=c2f(dummy_input)\n",
        "print(\"Output shape: \", dummy_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9HSnqDXZ8cV",
        "outputId": "6460c38f-c974-490a-937c-59b94a555693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18944 million parameters\n",
            "Output shape:  torch.Size([1, 128, 244, 244])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) SPPF**"
      ],
      "metadata": {
        "id": "ZalyGb2saSIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SPPF(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=5):\n",
        "        #kernel_size= size of maxpool\n",
        "        super().__init__()\n",
        "        hidden_channels=in_channels//2\n",
        "        self.conv1=Conv(in_channels,hidden_channels,kernel_size=1,stride=1,padding=0)\n",
        "        # concatenate outputs of maxpool and feed to conv2\n",
        "        self.conv2=Conv(4*hidden_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
        "\n",
        "        # maxpool is applied at 3 different sacles\n",
        "        self.m=nn.MaxPool2d(kernel_size=kernel_size,stride=1,padding=kernel_size//2,dilation=1,ceil_mode=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv1(x)\n",
        "\n",
        "        # apply maxpooling at diffent scales\n",
        "        y1=self.m(x)\n",
        "        y2=self.m(y1)\n",
        "        y3=self.m(y2)\n",
        "\n",
        "        # concantenate\n",
        "        y=torch.cat([x,y1,y2,y3],dim=1)\n",
        "\n",
        "        # final conv\n",
        "        y=self.conv2(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "# sanity check\n",
        "sppf=SPPF(in_channels=128,out_channels=512)\n",
        "print(f\"{sum(p.numel() for p in sppf.parameters())/1e6} million parameters\")\n",
        "\n",
        "dummy_input=sppf(dummy_input)\n",
        "print(\"Output shape: \", dummy_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fyjfZr_ZzPf",
        "outputId": "3d651947-c8ab-41ef-b84d-a5c61e5fbed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.140416 million parameters\n",
            "Output shape:  torch.Size([1, 512, 244, 244])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone = DarkNet53\n",
        "\n",
        "# return d,w,r based on version\n",
        "def yolo_params(version):\n",
        "    if version=='n':\n",
        "        return 1/3,1/4,2.0\n",
        "    elif version=='s':\n",
        "        return 1/3,1/2,2.0\n",
        "    elif version=='m':\n",
        "        return 2/3,3/4,1.5\n",
        "    elif version=='l':\n",
        "        return 1.0,1.0,1.0\n",
        "    elif version=='x':\n",
        "        return 1.0,1.25,1.0\n",
        "\n",
        "class Backbone(nn.Module):\n",
        "    def __init__(self,version,in_channels=3,shortcut=True):\n",
        "        super().__init__()\n",
        "        d,w,r=yolo_params(version)\n",
        "\n",
        "        # conv layers\n",
        "        self.conv_0=Conv(in_channels,int(64*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_1=Conv(int(64*w),int(128*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_3=Conv(int(128*w),int(256*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_5=Conv(int(256*w),int(512*w),kernel_size=3,stride=2,padding=1)\n",
        "        self.conv_7=Conv(int(512*w),int(512*w*r),kernel_size=3,stride=2,padding=1)\n",
        "\n",
        "        # c2f layers\n",
        "        self.c2f_2=C2f(int(128*w),int(128*w),num_bottlenecks=int(3*d),shortcut=True)\n",
        "        self.c2f_4=C2f(int(256*w),int(256*w),num_bottlenecks=int(6*d),shortcut=True)\n",
        "        self.c2f_6=C2f(int(512*w),int(512*w),num_bottlenecks=int(6*d),shortcut=True)\n",
        "        self.c2f_8=C2f(int(512*w*r),int(512*w*r),num_bottlenecks=int(3*d),shortcut=True)\n",
        "\n",
        "        # sppf\n",
        "        self.sppf=SPPF(int(512*w*r),int(512*w*r))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.conv_0(x)\n",
        "        x=self.conv_1(x)\n",
        "\n",
        "        x=self.c2f_2(x)\n",
        "\n",
        "        x=self.conv_3(x)\n",
        "\n",
        "        out1=self.c2f_4(x) # keep for output\n",
        "\n",
        "        x=self.conv_5(out1)\n",
        "\n",
        "        out2=self.c2f_6(x) # keep for output\n",
        "\n",
        "        x=self.conv_7(out2)\n",
        "        x=self.c2f_8(x)\n",
        "        out3=self.sppf(x)\n",
        "\n",
        "        return out1,out2,out3\n",
        "\n",
        "print(\"----Nano model -----\")\n",
        "backbone_n=Backbone(version='n')\n",
        "print(f\"{sum(p.numel() for p in backbone_n.parameters())/1e6} million parameters\")\n",
        "\n",
        "print(\"----Small model -----\")\n",
        "backbone_s=Backbone(version='s')\n",
        "print(f\"{sum(p.numel() for p in backbone_s.parameters())/1e6} million parameters\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe21TouyaZkK",
        "outputId": "65210b5f-6a58-4930-cd8c-f1b9941322fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----Nano model -----\n",
            "1.272656 million parameters\n",
            "----Small model -----\n",
            "5.079712 million parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "x=torch.rand((1,3,640,640))\n",
        "out1,out2,out3=backbone_n(x)\n",
        "print(out1.shape)\n",
        "print(out2.shape)\n",
        "print(out3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3GFjlkPaiua",
        "outputId": "beeafdfb-86e5-4cf7-e6d9-0f87b9b489d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 80, 80])\n",
            "torch.Size([1, 128, 40, 40])\n",
            "torch.Size([1, 256, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Neck**\n",
        "The neck comprises of Upsample + C2f with\n",
        "\n",
        "Upsample = nearest-neighbor interpolation with scale_factor=2. It doesn't have trainable paramaters."
      ],
      "metadata": {
        "id": "OSz1vDcgao4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upsample = nearest-neighbor interpolation with scale_factor=2\n",
        "#            doesn't have trainable paramaters\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self,scale_factor=2,mode='nearest'):\n",
        "        super().__init__()\n",
        "        self.scale_factor=scale_factor\n",
        "        self.mode=mode\n",
        "\n",
        "    def forward(self,x):\n",
        "        return nn.functional.interpolate(x,scale_factor=self.scale_factor,mode=self.mode)"
      ],
      "metadata": {
        "id": "yqXoNk8qazHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Neck(nn.Module):\n",
        "    def __init__(self,version):\n",
        "        super().__init__()\n",
        "        d,w,r=yolo_params(version)\n",
        "\n",
        "        self.up=Upsample() # no trainable parameters\n",
        "        self.c2f_1=C2f(in_channels=int(512*w*(1+r)), out_channels=int(512*w),num_bottlenecks=int(3*d),shortcut=False)\n",
        "        self.c2f_2=C2f(in_channels=int(768*w), out_channels=int(256*w),num_bottlenecks=int(3*d),shortcut=False)\n",
        "        self.c2f_3=C2f(in_channels=int(768*w), out_channels=int(512*w),num_bottlenecks=int(3*d),shortcut=False)\n",
        "        self.c2f_4=C2f(in_channels=int(512*w*(1+r)), out_channels=int(512*w*r),num_bottlenecks=int(3*d),shortcut=False)\n",
        "\n",
        "        self.cv_1=Conv(in_channels=int(256*w),out_channels=int(256*w),kernel_size=3,stride=2, padding=1)\n",
        "        self.cv_2=Conv(in_channels=int(512*w),out_channels=int(512*w),kernel_size=3,stride=2, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self,x_res_1,x_res_2,x):\n",
        "        # x_res_1,x_res_2,x = output of backbone\n",
        "        res_1=x              # for residual connection\n",
        "\n",
        "        x=self.up(x)\n",
        "        x=torch.cat([x,x_res_2],dim=1)\n",
        "\n",
        "        res_2=self.c2f_1(x)  # for residual connection\n",
        "\n",
        "        x=self.up(res_2)\n",
        "        x=torch.cat([x,x_res_1],dim=1)\n",
        "\n",
        "        out_1=self.c2f_2(x)\n",
        "\n",
        "        x=self.cv_1(out_1)\n",
        "\n",
        "        x=torch.cat([x,res_2],dim=1)\n",
        "        out_2=self.c2f_3(x)\n",
        "\n",
        "        x=self.cv_2(out_2)\n",
        "\n",
        "        x=torch.cat([x,res_1],dim=1)\n",
        "        out_3=self.c2f_4(x)\n",
        "\n",
        "        return out_1,out_2,out_3\n",
        "\n",
        "# sanity check\n",
        "neck=Neck(version='n')\n",
        "print(f\"{sum(p.numel() for p in neck.parameters())/1e6} million parameters\")\n",
        "\n",
        "x=torch.rand((1,3,640,640))\n",
        "out1,out2,out3=Backbone(version='n')(x)\n",
        "out_1,out_2,out_3=neck(out1,out2,out3)\n",
        "print(out_1.shape)\n",
        "print(out_2.shape)\n",
        "print(out_3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MePo5eKOamoS",
        "outputId": "e43d9766-2cd9-49b8-915a-a42bd915f60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98688 million parameters\n",
            "torch.Size([1, 64, 80, 80])\n",
            "torch.Size([1, 128, 40, 40])\n",
            "torch.Size([1, 256, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Head**\n",
        "Consist of 3 modules: (1) bbox coordinates, (2) classification scores, (3) distribution focal loss (DFL).\n",
        "\n",
        "DFL considers the predicted bbox coordinates as a probability distribution. At inference time, it samples from the distribution to get refined coordinates\n",
        ". For example, to predict coordinate\n",
        " in the normalized range\n",
        ":\n",
        "\n",
        "DFL uses 16 bins which are equally spaced in\n",
        ", bin length = 1/16.\n",
        "The model outputs 16 numbers which corresponds to probabilities that x falls in these bins, for example,\n",
        ".\n",
        "Prediction for\n",
        " mean value"
      ],
      "metadata": {
        "id": "dgLHfHGYbM_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (a) **DFL**"
      ],
      "metadata": {
        "id": "QzrvDc8BbUPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DFL\n",
        "class DFL(nn.Module):\n",
        "    def __init__(self,ch=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ch=ch\n",
        "\n",
        "        self.conv=nn.Conv2d(in_channels=ch,out_channels=1,kernel_size=1,bias=False).requires_grad_(False)\n",
        "\n",
        "        # initialize conv with [0,...,ch-1]\n",
        "        x=torch.arange(ch,dtype=torch.float).view(1,ch,1,1)\n",
        "        self.conv.weight.data[:]=torch.nn.Parameter(x) # DFL only has ch parameters\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x must have num_channels = 4*ch: x=[bs,4*ch,c]\n",
        "        b,c,a=x.shape                           # c=4*ch\n",
        "        x=x.view(b,4,self.ch,a).transpose(1,2)  # [bs,ch,4,a]\n",
        "\n",
        "        # take softmax on channel dimension to get distribution probabilities\n",
        "        x=x.softmax(1)                          # [b,ch,4,a]\n",
        "        x=self.conv(x)                          # [b,1,4,a]\n",
        "        return x.view(b,4,a)                    # [b,4,a]\n",
        "\n",
        "# sanity check\n",
        "dummy_input=torch.rand((1,64,128))\n",
        "dfl=DFL()\n",
        "print(f\"{sum(p.numel() for p in dfl.parameters())} parameters\")\n",
        "\n",
        "dummy_output=dfl(dummy_input)\n",
        "print(dummy_output.shape)\n",
        "\n",
        "print(dfl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVedXpsZa6XW",
        "outputId": "51888fb1-cf3c-4ed3-c768-58dacc806d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 parameters\n",
            "torch.Size([1, 4, 128])\n",
            "DFL(\n",
            "  (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self,version,ch=16,num_classes=80):\n",
        "\n",
        "        super().__init__()\n",
        "        self.ch=ch                          # dfl channels\n",
        "        self.coordinates=self.ch*4          # number of bounding box coordinates\n",
        "        self.nc=num_classes                 # 80 for COCO\n",
        "        self.no=self.coordinates+self.nc    # number of outputs per anchor box\n",
        "\n",
        "        self.stride=torch.zeros(3)          # strides computed during build\n",
        "\n",
        "        d,w,r=yolo_params(version=version)\n",
        "\n",
        "        # for bounding boxes\n",
        "        self.box=nn.ModuleList([\n",
        "            nn.Sequential(Conv(int(256*w),self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.coordinates,self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.coordinates,self.coordinates,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w),self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.coordinates,self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.coordinates,self.coordinates,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w*r),self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.coordinates,self.coordinates,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.coordinates,self.coordinates,kernel_size=1,stride=1))\n",
        "        ])\n",
        "\n",
        "        # for classification\n",
        "        self.cls=nn.ModuleList([\n",
        "            nn.Sequential(Conv(int(256*w),self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.nc,self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.nc,self.nc,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w),self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.nc,self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.nc,self.nc,kernel_size=1,stride=1)),\n",
        "\n",
        "            nn.Sequential(Conv(int(512*w*r),self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          Conv(self.nc,self.nc,kernel_size=3,stride=1,padding=1),\n",
        "                          nn.Conv2d(self.nc,self.nc,kernel_size=1,stride=1))\n",
        "        ])\n",
        "\n",
        "        # dfl\n",
        "        self.dfl=DFL()\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x = output of Neck = list of 3 tensors with different resolution and different channel dim\n",
        "        #     x[0]=[bs, ch0, w0, h0], x[1]=[bs, ch1, w1, h1], x[2]=[bs,ch2, w2, h2]\n",
        "\n",
        "        for i in range(len(self.box)):       # detection head i\n",
        "            box=self.box[i](x[i])            # [bs,num_coordinates,w,h]\n",
        "            cls=self.cls[i](x[i])            # [bs,num_classes,w,h]\n",
        "            x[i]=torch.cat((box,cls),dim=1)  # [bs,num_coordinates+num_classes,w,h]\n",
        "\n",
        "        # in training, no dfl output\n",
        "        if self.training:\n",
        "            return x                         # [3,bs,num_coordinates+num_classes,w,h]\n",
        "\n",
        "        # in inference time, dfl produces refined bounding box coordinates\n",
        "        anchors, strides = (i.transpose(0, 1) for i in self.make_anchors(x, self.stride))\n",
        "\n",
        "        # concatenate predictions from all detection layers\n",
        "        x = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], dim=2) #[bs, 4*self.ch + self.nc, sum_i(h[i]w[i])]\n",
        "\n",
        "        # split out predictions for box and cls\n",
        "        #           box=[bs,4×self.ch,sum_i(h[i]w[i])]\n",
        "        #           cls=[bs,self.nc,sum_i(h[i]w[i])]\n",
        "        box, cls = x.split(split_size=(4 * self.ch, self.nc), dim=1)\n",
        "\n",
        "\n",
        "        a, b = self.dfl(box).chunk(2, 1)  # a=b=[bs,2×self.ch,sum_i(h[i]w[i])]\n",
        "        a = anchors.unsqueeze(0) - a\n",
        "        b = anchors.unsqueeze(0) + b\n",
        "        box = torch.cat(tensors=((a + b) / 2, b - a), dim=1)\n",
        "\n",
        "        return torch.cat(tensors=(box * strides, cls.sigmoid()), dim=1)\n",
        "\n",
        "\n",
        "    def make_anchors(self, x, strides, offset=0.5):\n",
        "        # x= list of feature maps: x=[x[0],...,x[N-1]], in our case N= num_detection_heads=3\n",
        "        #                          each having shape [bs,ch,w,h]\n",
        "        #    each feature map x[i] gives output[i] = w*h anchor coordinates + w*h stride values\n",
        "\n",
        "        # strides = list of stride values indicating how much\n",
        "        #           the spatial resolution of the feature map is reduced compared to the original image\n",
        "\n",
        "        assert x is not None\n",
        "        anchor_tensor, stride_tensor = [], []\n",
        "        dtype, device = x[0].dtype, x[0].device\n",
        "        for i, stride in enumerate(strides):\n",
        "            _, _, h, w = x[i].shape\n",
        "            sx = torch.arange(end=w, device=device, dtype=dtype) + offset  # x coordinates of anchor centers\n",
        "            sy = torch.arange(end=h, device=device, dtype=dtype) + offset  # y coordinates of anchor centers\n",
        "            sy, sx = torch.meshgrid(sy, sx)                                # all anchor centers\n",
        "            anchor_tensor.append(torch.stack((sx, sy), -1).view(-1, 2))\n",
        "            stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n",
        "        return torch.cat(anchor_tensor), torch.cat(stride_tensor)"
      ],
      "metadata": {
        "id": "g_xwuUp7bnK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOnMId8vbyDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}